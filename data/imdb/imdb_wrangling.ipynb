{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "729ecf95",
   "metadata": {},
   "source": [
    "# Movie Curiosities: Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d992de-bbdf-4d91-9e7c-23e5d76e72d5",
   "metadata": {},
   "source": [
    "This project can be considered the 'back-end' of my project *Movie curiosities: an IMDB exploration.* The `imdb_final.csv` dataset used in that project was created using different datasets that required a lot of cleaning and tinkering around. Here we'll go through the entire process. (If you want to read the exploration part instead, it's available both [with code](https://github.com/NicolaBagala/portfolio/blob/master/data/imdb/imdb_exploration.ipynb) and [code-free](https://github.com/NicolaBagala/portfolio/blob/master/data/imdb/codefree/imdb_exploration_codefree.ipynb).)\n",
    "\n",
    "The datasets we'll use are:\n",
    "\n",
    "- `imdb_movies.csv` contains data about 85,855 movies listed on IMDB, such as title, year of release, average score, budget, etc. I originally downloaded this from Kaggle, but since then, the [source](https://www.kaggle.com/stefanoleone992/imdb-extensive-dataset) is no longer available for some reason.\n",
    "-  `imdb_ratings.csv` contains rating data about the same 85,855 movies listed in the dataset above, such as total votes, mean scores, votes by age and sex, etc. (As above, the original Kaggle [source](https://www.kaggle.com/stefanoleone992/imdb-extensive-dataset) is no longer available.)\n",
    "- `hist_CPIs.csv` contains historical values of the consumer product index relative to the US dollar from 1913 to 2021. Used for currency conversion. I created this dataset from [this table](https://www.minneapolisfed.org/about-us/monetary-policy/inflation-calculator/consumer-price-index-1913-).\n",
    "\n",
    "Being `imdb_movies.csv` and `imdb_ratings.csv` the two main data sources, this project consists of two wrangling and cleaning phases, one for each, after which they'll be merged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd77b679-25a6-4ede-99eb-8c4be261d7ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "## First dataset: `imdb_movies`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e66172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicola 2\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "imdb = pd.read_csv(\"imdb_movies.csv\", header = 0)                                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3b7852",
   "metadata": {},
   "source": [
    "As we'll see in a moment, the warning above is due to mixed value types in the `year` column; some values are numbers, others are strings. We'll fix it later; for now, let's explore the dataset a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fda835e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 85855 entries, 0 to 85854\n",
      "Data columns (total 22 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   imdb_title_id          85855 non-null  object \n",
      " 1   title                  85855 non-null  object \n",
      " 2   original_title         85855 non-null  object \n",
      " 3   year                   85855 non-null  object \n",
      " 4   date_published         85855 non-null  object \n",
      " 5   genre                  85855 non-null  object \n",
      " 6   duration               85855 non-null  int64  \n",
      " 7   country                85791 non-null  object \n",
      " 8   language               85022 non-null  object \n",
      " 9   director               85768 non-null  object \n",
      " 10  writer                 84283 non-null  object \n",
      " 11  production_company     81400 non-null  object \n",
      " 12  actors                 85786 non-null  object \n",
      " 13  description            83740 non-null  object \n",
      " 14  avg_vote               85855 non-null  float64\n",
      " 15  votes                  85855 non-null  int64  \n",
      " 16  budget                 23710 non-null  object \n",
      " 17  usa_gross_income       15326 non-null  object \n",
      " 18  worlwide_gross_income  31016 non-null  object \n",
      " 19  metascore              13305 non-null  float64\n",
      " 20  reviews_from_users     78258 non-null  float64\n",
      " 21  reviews_from_critics   74058 non-null  float64\n",
      "dtypes: float64(4), int64(2), object(16)\n",
      "memory usage: 14.4+ MB\n"
     ]
    }
   ],
   "source": [
    "imdb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180cadc1-f714-4b7f-9bbc-1009e16f6289",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dropping unnecessary columns and renaming others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d01629a",
   "metadata": {},
   "source": [
    "Many of the columns aren't needed for the purposes of the main project, so we can drop them to make the dataset more manageable. Namely:\n",
    "- We can drop `title` and keep `original_title` instead.\n",
    "- `date_published` wouldn't be very useful, because every movie has several different publishing dates, depending on the country where it is released. This column only shows one such date; in contrast, according to [IMDB's FAQs](https://help.imdb.com/article/contribution/titles/release-dates/GVUUDEPJNAW6G35P#), `year` refers to the year of the movie's first release *ever*, so we can keep this and drop `date_published`.\n",
    "- `language`, `director`, `writer`, `production_company`, `actors`,  `description`, `reviews_from_users`, and `reviews_from_critics` aren't relevant for any of the questions I set out to answer in the main project, so off they go.\n",
    "- `usa_gross_income` is in general less informative than `worlwide_gross_income` and contains many more null values, so let's drop it and keep the latter instead.\n",
    "- To keep things simple, we'll work only with IMDB scores, so `metascore` can be dropped as well. \n",
    "\n",
    "\n",
    "However, before dropping anything, let's make a backup copy, in case we'll ever need to have a look at the entire dataset later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a71db58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 85855 entries, 0 to 85854\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   imdb_title_id          85855 non-null  object \n",
      " 1   original_title         85855 non-null  object \n",
      " 2   year                   85855 non-null  object \n",
      " 3   genre                  85855 non-null  object \n",
      " 4   duration               85855 non-null  int64  \n",
      " 5   country                85791 non-null  object \n",
      " 6   avg_vote               85855 non-null  float64\n",
      " 7   votes                  85855 non-null  int64  \n",
      " 8   budget                 23710 non-null  object \n",
      " 9   worlwide_gross_income  31016 non-null  object \n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Back up the dataset before dropping columns.\n",
    "imdb_backup = imdb.copy()\n",
    "\n",
    "# Drop unnecessary columns.\n",
    "cols_to_drop = ([\"title\", \"date_published\", \"language\", \"director\",\n",
    "                 \"writer\", \"production_company\", \"actors\", \"description\", \"usa_gross_income\", \n",
    "                 \"metascore\", \"reviews_from_users\", \"reviews_from_critics\"])\n",
    "imdb.drop(columns = cols_to_drop, inplace = True)\n",
    "imdb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c1157f",
   "metadata": {},
   "source": [
    "The names of some of the columns are too long or not sufficiently informative, so let's change them to something better. Also, let's capitalise them to more easily distinguish them from the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3fa31e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 85855 entries, 0 to 85854\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   ID            85855 non-null  object \n",
      " 1   TITLE         85855 non-null  object \n",
      " 2   RELEASE_YEAR  85855 non-null  object \n",
      " 3   GENRE         85855 non-null  object \n",
      " 4   LENGTH_MIN    85855 non-null  int64  \n",
      " 5   COUNTRY       85791 non-null  object \n",
      " 6   AVG_SCORE     85855 non-null  float64\n",
      " 7   VOTES         85855 non-null  int64  \n",
      " 8   BUDGET        23710 non-null  object \n",
      " 9   GLOBAL_GROSS  31016 non-null  object \n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "new_names = {\"imdb_title_id\": \"ID\",\n",
    "             \"original_title\": \"TITLE\",\n",
    "             \"year\": \"RELEASE_YEAR\", \n",
    "             \"duration\":\"LENGTH_MIN\", # _MIN is just to be sure I remember how it's measured! \n",
    "             \"avg_vote\": \"AVG_SCORE\", # See below about this change\n",
    "             \"worlwide_gross_income\": \"GLOBAL_GROSS\"}\n",
    "\n",
    "imdb.rename(columns = new_names, inplace = True)\n",
    "imdb.columns = imdb.columns.str.upper() # Capitalise everything, because I didn't manually change every name\n",
    "imdb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e02cd54-b446-45c7-ad97-7c0f0c237c36",
   "metadata": {},
   "source": [
    "It should be noted that I changed the column `avg_vote` to `AVG_SCORE`. The reason for that was to avoid confusion later on, when handling the `imdb_ratings` dataset. On IMDB, every movie has an average score from 1 to 10, which is based on how the users scored that movie. For example, say that ten users give a certain movie score 5, two  give it score 8, and three give it score 9; in total, the movie has received 15 *votes*, which the IMDB backend then uses to compute an average *score* for the movie. Both the `imdb` dataset and the `imdb_ratings` dataset conflate the concept of \"score\" and \"user vote\", which I find confusing, hence the renaming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b45236",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Handling problematic values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5983b23-d072-4e47-a8a8-ca19e59084d4",
   "metadata": {},
   "source": [
    "In this section, we'll handle missing values and any other value that causes or might cause trouble later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d90238-199f-489e-9aea-8b420d8d963c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Release years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16dbce5-725b-4dd2-b21d-c40d36026fee",
   "metadata": {},
   "source": [
    "`RELEASE_YEAR` triggered a warning right upon loading the dataset. As said, that's because it contains a mix of integers and strings; one in particular definitely can't be typecasted to a numeric type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ddd5aa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1894, 1906, 1911, 1912, 1919, 1913, 1914, 1915, 1916, 1917, 1918,\n",
       "       1920, 1921, 1924, 1922, 1923, 1925, 1926, 1935, 1927, 1928, 1983,\n",
       "       1929, 1930, 1932, 1931, 1937, 1938, 1933, 1934, 1936, 1940, 1939,\n",
       "       1942, 1943, 1941, 1948, 1944, 2001, 1946, 1945, 1947, 1973, 1949,\n",
       "       1950, 1952, 1951, 1962, 1953, 1954, 1955, 1961, 1956, 1958, 1957,\n",
       "       1959, 1960, 1963, 1965, 1971, 1964, 1966, 1968, 1967, 1969, 1976,\n",
       "       1970, 1979, 1972, 1981, 1978, 2000, 1989, 1975, 1974, 1986, 1990,\n",
       "       2018, 1977, 1982, 1980, 1993, 1984, 1985, 1988, 1987, 2005, 1991,\n",
       "       2002, 1994, 1992, 1995, 2017, 1997, 1996, 2006, 1999, 1998, 2007,\n",
       "       2008, 2003, 2004, 2010, 2009, 2011, 2013, 2012, 2016, 2015, 2014,\n",
       "       2019, 2020, '2012', '2015', '2009', '2013', '2018', '2014', '2017',\n",
       "       '2011', '2016', '1981', '1975', '2010', '1984', '2007', '2006',\n",
       "       '2001', '2004', '1979', '2019', '1967', '1978', '2003', '2005',\n",
       "       '1969', '1990', '1983', '2002', '1996', '2008', '1995', '1999',\n",
       "       '1974', '1993', '1998', '1989', '2020', '1966', '1956', '1962',\n",
       "       '1985', '2000', '1971', '1970', '1986', '1930', '1976', '1982',\n",
       "       '1992', '1963', '1994', '1964', '1997', '1987', '1980',\n",
       "       'TV Movie 2019', '1988'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb[\"RELEASE_YEAR\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539139b0",
   "metadata": {},
   "source": [
    "The uncastable culprit is \"TV Movie 2019\", at the very bottom of the output above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb4bc6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>RELEASE_YEAR</th>\n",
       "      <th>GENRE</th>\n",
       "      <th>LENGTH_MIN</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>AVG_SCORE</th>\n",
       "      <th>VOTES</th>\n",
       "      <th>BUDGET</th>\n",
       "      <th>GLOBAL_GROSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83917</th>\n",
       "      <td>tt8206668</td>\n",
       "      <td>Bad Education</td>\n",
       "      <td>TV Movie 2019</td>\n",
       "      <td>Biography, Comedy, Crime</td>\n",
       "      <td>108</td>\n",
       "      <td>USA</td>\n",
       "      <td>7.1</td>\n",
       "      <td>23973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID          TITLE   RELEASE_YEAR                     GENRE  \\\n",
       "83917  tt8206668  Bad Education  TV Movie 2019  Biography, Comedy, Crime   \n",
       "\n",
       "       LENGTH_MIN COUNTRY  AVG_SCORE  VOTES BUDGET GLOBAL_GROSS  \n",
       "83917         108     USA        7.1  23973    NaN          NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.query(\"RELEASE_YEAR == 'TV Movie 2019'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca4bd8c",
   "metadata": {},
   "source": [
    "The problematic value affects only one entry, [*Bad Education*](https://en.wikipedia.org/wiki/Bad_Education_(2019_film)), which was indeed released in 2019 as a TV movie. The fact that it's a TV movie isn't relevant for the scope of the analysis, so let's just correct it to `2019`, and then convert the whole column to `dtype: int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3547ceb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1894, 1906, 1911, 1912, 1919, 1913, 1914, 1915, 1916, 1917, 1918,\n",
       "       1920, 1921, 1924, 1922, 1923, 1925, 1926, 1935, 1927, 1928, 1983,\n",
       "       1929, 1930, 1932, 1931, 1937, 1938, 1933, 1934, 1936, 1940, 1939,\n",
       "       1942, 1943, 1941, 1948, 1944, 2001, 1946, 1945, 1947, 1973, 1949,\n",
       "       1950, 1952, 1951, 1962, 1953, 1954, 1955, 1961, 1956, 1958, 1957,\n",
       "       1959, 1960, 1963, 1965, 1971, 1964, 1966, 1968, 1967, 1969, 1976,\n",
       "       1970, 1979, 1972, 1981, 1978, 2000, 1989, 1975, 1974, 1986, 1990,\n",
       "       2018, 1977, 1982, 1980, 1993, 1984, 1985, 1988, 1987, 2005, 1991,\n",
       "       2002, 1994, 1992, 1995, 2017, 1997, 1996, 2006, 1999, 1998, 2007,\n",
       "       2008, 2003, 2004, 2010, 2009, 2011, 2013, 2012, 2016, 2015, 2014,\n",
       "       2019, 2020])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.at[83917, \"RELEASE_YEAR\"] = 2019\n",
    "imdb[\"RELEASE_YEAR\"] = imdb[\"RELEASE_YEAR\"].astype(int)\n",
    "imdb[\"RELEASE_YEAR\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f246963-0359-4835-bfa3-e86081625405",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b256752f-738d-4b4c-a45e-287fa6edd18a",
   "metadata": {},
   "source": [
    "In order to make sure there aren't any absurd movie lengths, let's check the minimum and maximum values of `LENGTH_MIN`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8f28ddd-7120-4264-8f8c-ebeeb6e791c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 41; Max: 808\n"
     ]
    }
   ],
   "source": [
    "print(\"Min: {}; Max: {}\".format(imdb[\"LENGTH_MIN\"].min(),imdb[\"LENGTH_MIN\"].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8805a237-f98f-4c65-a8b2-03068b141b60",
   "metadata": {},
   "source": [
    "41 minutes is not at all a weird length, but 808 definitely is. What is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e120c41-191a-4491-8a20-eaaebdc8c317",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85057    La flor\n",
       "Name: TITLE, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.loc[imdb[\"LENGTH_MIN\"] == 808, \"TITLE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf51467-d18e-4f4b-a23a-b8b0729c3f78",
   "metadata": {},
   "source": [
    "Apparently, a movie that long [actually exists](https://en.wikipedia.org/wiki/La_Flor). Given that, there's no reason to doubt other lengths, because they're all shorter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c516b43d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Possible misspellings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0641bf9-f00e-429a-ace5-d7faafc6162e",
   "metadata": {},
   "source": [
    "The only text columns are `TITLE`, `GENRE`, and `COUNTRY`. Any misspellings in the `TITLE` column don't really matter, as we'll keep titles only for reference; however, errors in the other two columns might be problematic, for examples if the same country had multiple (mis)spellings, such as \"USA\" and \"US\", or if the same genre was spelled \"Drama\" in one place and \"Drma\" in another. To see whether there's any issue like that, let's print out each single, unique genre and country and inspect them visually. The two utility functions below will help us do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a404a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_list(string_list):\n",
    "    \"\"\"Turns a string-list such as \"A, B, C\" into an actual list object, [\"A\", \"B\", \"C\"]\n",
    "    `string_list` is a string to be turned to an actual list.\n",
    "    \"\"\"    \n",
    "    # If string_list doesn't contain a comma, it's a single entry.\n",
    "    if \",\" not in string_list: return [string_list]        \n",
    "    \n",
    "    # If string_list does contain a comma, it's a string-list of entries.\n",
    "    string_list = string_list.split(\",\")\n",
    "    actual_list = []\n",
    "    for item in string_list:\n",
    "        actual_list.append(item.strip())\n",
    "    return actual_list\n",
    "    \n",
    "def add_to_set(orig_list, dest_set):\n",
    "    \"\"\"Adds every item of a list to a set, to guarantee uniqueness.\n",
    "    `orig_list` is a list (or iterable).\n",
    "    `dest_set` is the destination set to which items of `orig_list` must be added.\n",
    "    \"\"\"\n",
    "    for item in orig_list:\n",
    "        dest_set.add(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3bb4e0",
   "metadata": {},
   "source": [
    "As we've seen above, `GENRE` doesn't have any nulls, nor any particularly problematic values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70f504c5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Action',\n",
       " 'Adult',\n",
       " 'Adventure',\n",
       " 'Animation',\n",
       " 'Biography',\n",
       " 'Comedy',\n",
       " 'Crime',\n",
       " 'Documentary',\n",
       " 'Drama',\n",
       " 'Family',\n",
       " 'Fantasy',\n",
       " 'Film-Noir',\n",
       " 'History',\n",
       " 'Horror',\n",
       " 'Music',\n",
       " 'Musical',\n",
       " 'Mystery',\n",
       " 'News',\n",
       " 'Reality-TV',\n",
       " 'Romance',\n",
       " 'Sci-Fi',\n",
       " 'Sport',\n",
       " 'Thriller',\n",
       " 'War',\n",
       " 'Western'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find unique genres across the dataset.\n",
    "unique_genre_strings = pd.Series(imdb[\"GENRE\"].unique()) \n",
    "unique_genre_lists = unique_genre_strings.map(string_to_list)\n",
    "\n",
    "unique_genres = set()\n",
    "unique_genre_lists.apply(add_to_set, args = (unique_genres,)) \n",
    "unique_genres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbc656a",
   "metadata": {},
   "source": [
    "I don't like the hyphenation of a couple of genres, so I'll change that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af7ec5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb[\"GENRE\"] = imdb[\"GENRE\"].map(lambda x: x.replace(\"Film-Noir\", \"Film noir\"))\n",
    "imdb[\"GENRE\"] = imdb[\"GENRE\"].map(lambda x: x.replace(\"Reality-TV\", \"Reality TV\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6ff66c",
   "metadata": {},
   "source": [
    "Before we can move on to look for spelling issues with the country names, we have to fix the missing values in the `COUNTRY` column, which if left alone would break the function `string_to_list`. (`GENRE` didn't have any nulls, which is why we didn't have to worry about that before.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0da1ec8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing COUNTRY values: 64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing COUNTRY values: {}\".format(imdb[\"COUNTRY\"].isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ebf6d",
   "metadata": {},
   "source": [
    "Seeing as how there are \"only\" 64 movies with a missing values for `COUNTRY`, for it's tempting to look them up and write down the country; I tried that, but they turned out to be mostly indie, obscure movies for which finding the country would be a time sink. It's best to mark them as `(Missing)` instead and move on with the misspelling check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63efa898",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(Missing)',\n",
       " 'Afghanistan',\n",
       " 'Albania',\n",
       " 'Algeria',\n",
       " 'Andorra',\n",
       " 'Angola',\n",
       " 'Argentina',\n",
       " 'Armenia',\n",
       " 'Aruba',\n",
       " 'Australia',\n",
       " 'Austria',\n",
       " 'Azerbaijan',\n",
       " 'Bahamas',\n",
       " 'Bahrain',\n",
       " 'Bangladesh',\n",
       " 'Belarus',\n",
       " 'Belgium',\n",
       " 'Belize',\n",
       " 'Bermuda',\n",
       " 'Bhutan',\n",
       " 'Bolivia',\n",
       " 'Bosnia and Herzegovina',\n",
       " 'Botswana',\n",
       " 'Brazil',\n",
       " 'British Virgin Islands',\n",
       " 'Brunei',\n",
       " 'Bulgaria',\n",
       " 'Burkina Faso',\n",
       " 'Burma',\n",
       " 'Cambodia',\n",
       " 'Cameroon',\n",
       " 'Canada',\n",
       " 'Cape Verde',\n",
       " 'Cayman Islands',\n",
       " 'Chad',\n",
       " 'Chile',\n",
       " 'China',\n",
       " 'Colombia',\n",
       " 'Cook Islands',\n",
       " 'Costa Rica',\n",
       " 'Croatia',\n",
       " 'Cuba',\n",
       " 'Cyprus',\n",
       " 'Czech Republic',\n",
       " 'Czechoslovakia',\n",
       " \"Côte d'Ivoire\",\n",
       " 'Denmark',\n",
       " 'Djibouti',\n",
       " 'Dominican Republic',\n",
       " 'East Germany',\n",
       " 'Ecuador',\n",
       " 'Egypt',\n",
       " 'El Salvador',\n",
       " 'Equatorial Guinea',\n",
       " 'Estonia',\n",
       " 'Ethiopia',\n",
       " 'Faroe Islands',\n",
       " 'Federal Republic of Yugoslavia',\n",
       " 'Fiji',\n",
       " 'Finland',\n",
       " 'France',\n",
       " 'Gabon',\n",
       " 'Georgia',\n",
       " 'Germany',\n",
       " 'Ghana',\n",
       " 'Gibraltar',\n",
       " 'Greece',\n",
       " 'Greenland',\n",
       " 'Guadeloupe',\n",
       " 'Guatemala',\n",
       " 'Guinea',\n",
       " 'Guinea-Bissau',\n",
       " 'Haiti',\n",
       " 'Holy See (Vatican City State)',\n",
       " 'Honduras',\n",
       " 'Hong Kong',\n",
       " 'Hungary',\n",
       " 'Iceland',\n",
       " 'India',\n",
       " 'Indonesia',\n",
       " 'Iran',\n",
       " 'Iraq',\n",
       " 'Ireland',\n",
       " 'Isle Of Man',\n",
       " 'Israel',\n",
       " 'Italy',\n",
       " 'Jamaica',\n",
       " 'Japan',\n",
       " 'Jordan',\n",
       " 'Kazakhstan',\n",
       " 'Kenya',\n",
       " 'Korea',\n",
       " 'Kosovo',\n",
       " 'Kuwait',\n",
       " 'Kyrgyzstan',\n",
       " 'Laos',\n",
       " 'Latvia',\n",
       " 'Lebanon',\n",
       " 'Lesotho',\n",
       " 'Liberia',\n",
       " 'Libya',\n",
       " 'Liechtenstein',\n",
       " 'Lithuania',\n",
       " 'Luxembourg',\n",
       " 'Macao',\n",
       " 'Malawi',\n",
       " 'Malaysia',\n",
       " 'Maldives',\n",
       " 'Mali',\n",
       " 'Malta',\n",
       " 'Martinique',\n",
       " 'Mauritania',\n",
       " 'Mauritius',\n",
       " 'Mexico',\n",
       " 'Moldova',\n",
       " 'Monaco',\n",
       " 'Mongolia',\n",
       " 'Montenegro',\n",
       " 'Morocco',\n",
       " 'Mozambique',\n",
       " 'Myanmar',\n",
       " 'Namibia',\n",
       " 'Nepal',\n",
       " 'Netherlands',\n",
       " 'Netherlands Antilles',\n",
       " 'New Caledonia',\n",
       " 'New Zealand',\n",
       " 'Nicaragua',\n",
       " 'Niger',\n",
       " 'Nigeria',\n",
       " 'North Korea',\n",
       " 'North Vietnam',\n",
       " 'Norway',\n",
       " 'Oman',\n",
       " 'Pakistan',\n",
       " 'Palestine',\n",
       " 'Panama',\n",
       " 'Papua New Guinea',\n",
       " 'Paraguay',\n",
       " 'Peru',\n",
       " 'Philippines',\n",
       " 'Poland',\n",
       " 'Portugal',\n",
       " 'Puerto Rico',\n",
       " 'Qatar',\n",
       " 'Republic of North Macedonia',\n",
       " 'Reunion',\n",
       " 'Romania',\n",
       " 'Russia',\n",
       " 'Rwanda',\n",
       " 'Samoa',\n",
       " 'Saudi Arabia',\n",
       " 'Senegal',\n",
       " 'Serbia',\n",
       " 'Serbia and Montenegro',\n",
       " 'Singapore',\n",
       " 'Slovakia',\n",
       " 'Slovenia',\n",
       " 'Somalia',\n",
       " 'South Africa',\n",
       " 'South Korea',\n",
       " 'Soviet Union',\n",
       " 'Spain',\n",
       " 'Sri Lanka',\n",
       " 'Sudan',\n",
       " 'Suriname',\n",
       " 'Svalbard And Jan Mayen',\n",
       " 'Swaziland',\n",
       " 'Sweden',\n",
       " 'Switzerland',\n",
       " 'Syria',\n",
       " 'Taiwan',\n",
       " 'Tajikistan',\n",
       " 'Tanzania',\n",
       " 'Thailand',\n",
       " 'The Democratic Republic Of Congo',\n",
       " 'Trinidad and Tobago',\n",
       " 'Tunisia',\n",
       " 'Turkey',\n",
       " 'UK',\n",
       " 'USA',\n",
       " 'Uganda',\n",
       " 'Ukraine',\n",
       " 'United Arab Emirates',\n",
       " 'Uruguay',\n",
       " 'Uzbekistan',\n",
       " 'Vanuatu',\n",
       " 'Venezuela',\n",
       " 'Vietnam',\n",
       " 'West Germany',\n",
       " 'Yemen',\n",
       " 'Yugoslavia',\n",
       " 'Zaire',\n",
       " 'Zambia',\n",
       " 'Zimbabwe'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb[\"COUNTRY\"].fillna(\"(Missing)\", inplace = True)\n",
    "\n",
    "unique_country_strings = pd.Series(imdb[\"COUNTRY\"].unique())\n",
    "unique_country_lists = unique_country_strings.map(string_to_list)\n",
    "\n",
    "unique_countries = set()\n",
    "unique_country_lists.apply(add_to_set, args = (unique_countries,)) \n",
    "unique_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e59ed1a",
   "metadata": {},
   "source": [
    "There are only two names that could be shortened. No other obvious issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a20d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb[\"COUNTRY\"] = imdb[\"COUNTRY\"].map(lambda x: x.replace(\"Holy See (Vatican City State)\", \"Vatican City\"))\n",
    "imdb[\"COUNTRY\"] = imdb[\"COUNTRY\"].map(lambda x: x.replace(\"The Democratic Republic Of Congo\", \"Democratic Republic Of Congo\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3178aadf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Redundancies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ea02c8-adc4-4113-bfb7-62c916ff31a7",
   "metadata": {},
   "source": [
    "The columns `GENRE` and `COUNTRY` might contain multiple values for the same entry, because a movie can have several genres and be the product of a multi-country collaboration. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75d7f620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      Romance\n",
       "1      Biography, Crime, Drama\n",
       "2                        Drama\n",
       "3               Drama, History\n",
       "4    Adventure, Drama, Fantasy\n",
       "Name: GENRE, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb[\"GENRE\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c1f8c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 USA\n",
       "1           Australia\n",
       "2    Germany, Denmark\n",
       "3                 USA\n",
       "4               Italy\n",
       "Name: COUNTRY, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb[\"COUNTRY\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010446f5",
   "metadata": {},
   "source": [
    "The problem with that is that two such lists could be conceptually identical while being technically different; for example, `Comedy, Drama` and `Drama, Comedy` identify the same two genres, but they are two different strings. There are cases like this in both the `GENRE` and `COUNTRY` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb99cdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Comedy, Drama': 4039\n",
      "'Drama, Comedy': 124\n"
     ]
    }
   ],
   "source": [
    "comedy_drama = imdb.loc[imdb[\"GENRE\"] == \"Comedy, Drama\", \"GENRE\"].size\n",
    "drama_comedy = imdb.loc[imdb[\"GENRE\"] == \"Drama, Comedy\", \"GENRE\"].size\n",
    "\n",
    "print(\"'Comedy, Drama':\", comedy_drama)\n",
    "print(\"'Drama, Comedy':\", drama_comedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b33e175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Germany, Denmark': 7\n",
      "'Denmark, Germany': 10\n"
     ]
    }
   ],
   "source": [
    "ger_den = imdb.loc[imdb[\"COUNTRY\"] == \"Germany, Denmark\", \"COUNTRY\"].size\n",
    "den_ger = imdb.loc[imdb[\"COUNTRY\"] == \"Denmark, Germany\", \"COUNTRY\"].size\n",
    "\n",
    "print(\"'Germany, Denmark':\", ger_den)\n",
    "print(\"'Denmark, Germany':\", den_ger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713a2e61",
   "metadata": {},
   "source": [
    "We can fix that by sorting each list alphabetically, using the utility function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ebff964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphasort_string(string):\n",
    "    \"\"\"Takes in a string of the form \"item1, item2, item3, ...\" and returns a string\n",
    "    where the item1, item2, item3, ..., have been sorted alphabetically.\n",
    "    \n",
    "    `string` is a string whose comma-separated entries need to be sorted alphabetically.\n",
    "    \"\"\"\n",
    "    items = string.split(\",\")    \n",
    "    sorted_items = []\n",
    "    for item in items:\n",
    "        stripped_item = item.strip() \n",
    "        sorted_items.append(stripped_item)  \n",
    "        \n",
    "    sorted_items.sort()\n",
    "    # Convert `sorted_items` to a string, and eliminate any extra brackets or single-quotes left. \n",
    "    sorted_items = str(sorted_items).strip(\"[]\").replace(\"'\", \"\") \n",
    "    return sorted_items\n",
    "\n",
    "# Sort all lists in the `GENRE` and `COUNTRY` columns alphabetically. \n",
    "imdb[\"GENRE\"] = imdb[\"GENRE\"].map(alphasort_string)\n",
    "imdb[\"COUNTRY\"] = imdb[\"COUNTRY\"].map(alphasort_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f95797-65d5-4410-90b9-331c80f947f3",
   "metadata": {},
   "source": [
    "To make sure it worked, let's check how many entries whose `GENRE` is `Comedy, Drama` or `Drama, Comedy` there are now. If everything worked as expected, all the 124 `Drama, Comedy` entries we had before should now be `Comedy, Drama` entries, whose total should be `4039 + 124 = 4163`. The total of `Drama, Comedy` entries should instead be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60232913-9ac2-4413-ab0a-9d6f49059aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Comedy, Drama': 4163\n",
      "'Drama, Comedy': 0\n"
     ]
    }
   ],
   "source": [
    "comedy_drama = imdb.loc[imdb[\"GENRE\"] == \"Comedy, Drama\", \"GENRE\"].size\n",
    "drama_comedy = imdb.loc[imdb[\"GENRE\"] == \"Drama, Comedy\", \"GENRE\"].size\n",
    "\n",
    "print(\"'Comedy, Drama':\", comedy_drama)\n",
    "print(\"'Drama, Comedy':\", drama_comedy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a93529",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bbe322-668e-4ef2-b2ec-c0c23c1f0229",
   "metadata": {},
   "source": [
    "Before doing any further work, it's best to make sure there are no duplicate entries. `ID`s should be different no matter what, so let's make sure that's the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd9db8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    85855\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb[\"ID\"].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b7c6c9",
   "metadata": {},
   "source": [
    "There are no duplicated IDs, but that doesn't mean there can't be duplicated *movies*. It's very much possible for two different movies to have the same title, so checking titles alone just won't cut it. It's also very much possible, however unlikely, that two different movies have the same `AVG_SCORE` or `VOTES`; `BUDGET` and `GLOBAL_GROSS` have far too many nulls to be useful to spot duplicates, so our best bet is to look for any movies that have the same `TITLE`, `RELEASE_YEAR`, `GENRE`, `LENGTH_MIN`, and `COUNTRY`. To prevent false positives or false negatives when checking the `TITLE`, we're going to make all titles lowercase first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b8fe21b-8b05-4658-9d01-a13126a94a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    85853\n",
       "True         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_duplicate_check = imdb[[\"TITLE\", \"RELEASE_YEAR\", \"GENRE\", \"LENGTH_MIN\", \"COUNTRY\"]].copy()\n",
    "\n",
    "# Format all titles uniformly.\n",
    "imdb_duplicate_check[\"TITLE\"] = imdb_duplicate_check[\"TITLE\"].map(str.lower).map(str.strip)\n",
    "\n",
    "# Check for duplicates over all fields. Find and report each and every instance of a potential duplicate `(keep = False)`.\n",
    "duplicates = imdb_duplicate_check.duplicated(keep = False)\n",
    "duplicates.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3961993-1a74-488b-91ee-e8903a3c0575",
   "metadata": {},
   "source": [
    "There are two potential duplicates; let's look them up in the original dataset through the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45184622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>RELEASE_YEAR</th>\n",
       "      <th>GENRE</th>\n",
       "      <th>LENGTH_MIN</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>AVG_SCORE</th>\n",
       "      <th>VOTES</th>\n",
       "      <th>BUDGET</th>\n",
       "      <th>GLOBAL_GROSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64199</th>\n",
       "      <td>tt2069797</td>\n",
       "      <td>Delirium</td>\n",
       "      <td>2018</td>\n",
       "      <td>Horror, Thriller</td>\n",
       "      <td>96</td>\n",
       "      <td>USA</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69971</th>\n",
       "      <td>tt3131050</td>\n",
       "      <td>Delirium</td>\n",
       "      <td>2018</td>\n",
       "      <td>Horror, Thriller</td>\n",
       "      <td>96</td>\n",
       "      <td>USA</td>\n",
       "      <td>3.2</td>\n",
       "      <td>739</td>\n",
       "      <td>$ 3000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID     TITLE  RELEASE_YEAR             GENRE  LENGTH_MIN  \\\n",
       "64199  tt2069797  Delirium          2018  Horror, Thriller          96   \n",
       "69971  tt3131050  Delirium          2018  Horror, Thriller          96   \n",
       "\n",
       "      COUNTRY  AVG_SCORE  VOTES     BUDGET GLOBAL_GROSS  \n",
       "64199     USA        5.7   6114        NaN          NaN  \n",
       "69971     USA        3.2    739  $ 3000000          NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_ids = duplicates[duplicates == True].index\n",
    "imdb.loc[duplicate_ids, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cfef43",
   "metadata": {},
   "source": [
    "Interestingly, there actually *are* two different movies from 2018 called *Delirium*, both from the USA, a duration of 96 minutes, and the same genre. ([Here](https://www.imdb.com/title/tt2069797/?ref_=fn_tt_tt_1) and [here](https://www.imdb.com/title/tt3131050/?ref_=fn_tt_tt_8) on IMDB.) Still, to be absolutely sure that the two rows above really do refer to different movies, we can look them up in the backup copy of the IMDB dataset that contains more columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eab79bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_title_id</th>\n",
       "      <th>title</th>\n",
       "      <th>original_title</th>\n",
       "      <th>year</th>\n",
       "      <th>date_published</th>\n",
       "      <th>genre</th>\n",
       "      <th>duration</th>\n",
       "      <th>country</th>\n",
       "      <th>language</th>\n",
       "      <th>director</th>\n",
       "      <th>...</th>\n",
       "      <th>actors</th>\n",
       "      <th>description</th>\n",
       "      <th>avg_vote</th>\n",
       "      <th>votes</th>\n",
       "      <th>budget</th>\n",
       "      <th>usa_gross_income</th>\n",
       "      <th>worlwide_gross_income</th>\n",
       "      <th>metascore</th>\n",
       "      <th>reviews_from_users</th>\n",
       "      <th>reviews_from_critics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64199</th>\n",
       "      <td>tt2069797</td>\n",
       "      <td>Delirium</td>\n",
       "      <td>Delirium</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-05-22</td>\n",
       "      <td>Horror, Thriller</td>\n",
       "      <td>96</td>\n",
       "      <td>USA</td>\n",
       "      <td>English</td>\n",
       "      <td>Dennis Iliadis</td>\n",
       "      <td>...</td>\n",
       "      <td>Genesis Rodriguez, Topher Grace, Patricia Clar...</td>\n",
       "      <td>A man recently released from a mental institut...</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69971</th>\n",
       "      <td>tt3131050</td>\n",
       "      <td>Delirium</td>\n",
       "      <td>Delirium</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-01-19</td>\n",
       "      <td>Horror, Thriller</td>\n",
       "      <td>96</td>\n",
       "      <td>USA</td>\n",
       "      <td>English</td>\n",
       "      <td>Johnny Martin</td>\n",
       "      <td>...</td>\n",
       "      <td>Mike C. Manning, Griffin Freeman, Ryan Pinksto...</td>\n",
       "      <td>A group of young men dare a classmate to reach...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>739</td>\n",
       "      <td>$ 3000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      imdb_title_id     title original_title  year date_published  \\\n",
       "64199     tt2069797  Delirium       Delirium  2018     2018-05-22   \n",
       "69971     tt3131050  Delirium       Delirium  2018     2018-01-19   \n",
       "\n",
       "                  genre  duration country language        director  ...  \\\n",
       "64199  Horror, Thriller        96     USA  English  Dennis Iliadis  ...   \n",
       "69971  Horror, Thriller        96     USA  English   Johnny Martin  ...   \n",
       "\n",
       "                                                  actors  \\\n",
       "64199  Genesis Rodriguez, Topher Grace, Patricia Clar...   \n",
       "69971  Mike C. Manning, Griffin Freeman, Ryan Pinksto...   \n",
       "\n",
       "                                             description avg_vote votes  \\\n",
       "64199  A man recently released from a mental institut...      5.7  6114   \n",
       "69971  A group of young men dare a classmate to reach...      3.2   739   \n",
       "\n",
       "          budget  usa_gross_income worlwide_gross_income metascore  \\\n",
       "64199        NaN               NaN                   NaN       NaN   \n",
       "69971  $ 3000000               NaN                   NaN      27.0   \n",
       "\n",
       "      reviews_from_users  reviews_from_critics  \n",
       "64199              102.0                  23.0  \n",
       "69971               19.0                   6.0  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_backup.loc[duplicate_ids, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce115e2",
   "metadata": {},
   "source": [
    "The two entries have different publishing dates, directors, and actors, so at this point we're sure that they're two different movies and that there shouldn't be any duplicates in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbca74ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Handling currency columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aa8dc7-85c6-4e68-b345-9a992ff39f10",
   "metadata": {},
   "source": [
    "Some of the questions I set out to answer require converting all amounts in the `BUDGET` and `GLOBAL_GROSS` columns into today's (2021, at the time of writing), inflation-adjusted USD (United States Dollars). We're operating on the (reasonable) assumption that the values in the `BUDGET` and `GLOBAL_GROSS` columns are relative to the year the movie was released. So, if a movie was released in 1950 and had a budget of, say, USD 50,000 and grossed USD 200,000 globally, we'd be talking 1950's USD, and similarly for any other currency. \n",
    "\n",
    "Adjusting for inflation from year $y$ to today isn't difficult; as explained [here](https://www.officialdata.org/us/inflation/1800?amount=1#formulas), it's enough to multiply each amount by \n",
    "\n",
    "$$\n",
    "r^{t}_{y}=\\frac{CPI_t}{CPI_y} \n",
    "$$\n",
    "\n",
    "where ${CPI}_t$ is today's [*consumer price index*](https://en.wikipedia.org/wiki/Consumer_price_index) and ${CPI}_y$ is the CPI from a past year $y$. In general, the value of $r^{t}_{y}$ is different for different currencies, because the rate of inflation experienced by different countries is different; so, we might need several different historical CPI records, depending on how many different currencies appeared in the `BUDGET` and `GLOBAL_GROSS` columns. (Converting every amount to a single, \"bridge\" currency, adjusting those amounts for inflation and converting back to the original currency doesn't work, precisely because inflation grows differently in different countries.)\n",
    "\n",
    "So, the next question is: how many currencies are there, and what format are they expressed in?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a7aeaa-fa84-4f37-a4a4-5d577a1887b0",
   "metadata": {},
   "source": [
    "#### Currency format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53c0bff-e9fe-4d8d-aa98-6e03f728e914",
   "metadata": {},
   "source": [
    "The `dtype` of both the `BUDGET` and `GLOBAL_GROSS` columns is `object`, and their non-null values appear to be composed of a currency symbol followed by a single space and then a figure. Most of the currency symbols are `$` signs, but the rest are three-letter strings, like `EUR` or `NOK`. Let's make sure this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ea61a3d-7e7d-4a4c-b54b-3757b5069bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget values that match the pattern OR are null: 85855 out of 85855\n",
      "Gross values that match the pattern OR are null: 85855 out of 85855\n"
     ]
    }
   ],
   "source": [
    "# Regex: match strings that begin EITHER with a single $ OR with exactly three letters, followed by a single space and any number of figures.\n",
    "pattern = r\"(^[$]|^[^0-9\\s$]{3}) [0-9]+\"\n",
    "\n",
    "# Consider nulls as True, so that any False will be each and every values that are NOT null AND do not match the pattern.\n",
    "budget_matches = imdb[\"BUDGET\"].str.fullmatch(pattern, na = True).value_counts()[True]\n",
    "print(\"Budget values that match the pattern OR are null: {} out of {}\".format(budget_matches, len(imdb)))      \n",
    "      \n",
    "gross_matches = imdb[\"GLOBAL_GROSS\"].str.fullmatch(pattern, na = True).value_counts()[True]\n",
    "print(\"Gross values that match the pattern OR are null: {} out of {}\".format(gross_matches, len(imdb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5d30d4",
   "metadata": {},
   "source": [
    "The `$` sign might be problematic, so it's best to replace it with the string `USD`. (This also makes our dataset more consistent.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba8620be",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb[\"BUDGET\"] = imdb[\"BUDGET\"].str.replace(r\"$\", \"USD\", regex = False)\n",
    "imdb[\"GLOBAL_GROSS\"] = imdb[\"GLOBAL_GROSS\"].str.replace(r\"$\", \"USD\", regex = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dcceb4",
   "metadata": {},
   "source": [
    "Now we can look at both columns to see what are all the currencies we're dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ad24938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'USD' 'ITL' 'ROL' 'SEK' 'FRF' 'NOK' 'GBP' 'DEM' 'PTE' 'FIM' 'CAD'\n",
      " 'INR' 'CHF' 'ESP' 'JPY' 'DKK' 'NLG' 'PLN' 'RUR' 'AUD' 'KRW' 'BEF' 'XAU'\n",
      " 'HKD' 'NZD' 'CNY' 'EUR' 'PYG' 'ISK' 'IEP' 'TRL' 'HRK' 'SIT' 'PHP' 'HUF'\n",
      " 'DOP' 'JMD' 'CZK' 'SGD' 'BRL' 'BDT' 'ATS' 'BND' 'EGP' 'THB' 'GRD' 'ZAR'\n",
      " 'NPR' 'IDR' 'PKR' 'MXN' 'BGL' 'EEK' 'YUM' 'MYR' 'IRR' 'CLP' 'SKK' 'LTL'\n",
      " 'TWD' 'MTL' 'LVL' 'COP' 'ARS' 'UAH' 'RON' 'ALL' 'NGN' 'ILS' 'VEB' 'VND'\n",
      " 'TTD' 'JOD' 'LKR' 'GEL' 'MNT' 'AZM' 'AMD' 'AED']\n"
     ]
    }
   ],
   "source": [
    "# Regex: extract anything that is NOT a number or a whitespace. (So, currency symbols.)\n",
    "currency_pattern = r\"([^0-9\\s]+)\"\n",
    "\n",
    "# This function looks too simple to bother with, but we'll use it again.\n",
    "def print_all_currencies():\n",
    "    \"\"\"Prints all unique currencies across both `BUDGET` and `GLOBAL_GROSS` columns. \"\"\"    \n",
    "    budget_currencies = imdb[\"BUDGET\"].str.extract(currency_pattern, expand = False)\n",
    "    gross_currencies = imdb[\"GLOBAL_GROSS\"].str.extract(currency_pattern, expand = False)\n",
    "    all_currencies = pd.concat([budget_currencies, gross_currencies], axis = 0).unique()\n",
    "    print(all_currencies)\n",
    "    \n",
    "print_all_currencies()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b58ac41",
   "metadata": {},
   "source": [
    "Finding historical CPI records for so many different currencies would be a bit of a nightmare, so we should consider the possibility of limiting the analysis to `USD` values only, which are likely the most frequent ones. Let's see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b674a1b7-953d-4536-b8d6-6c61d45e9c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-USD BUDGET values: 7108 out of 23710 non-null values. (30.0%)\n",
      "Non-USD GLOBAL_GROSS values: 61 out of 31016 non-null values. (0.2%)\n"
     ]
    }
   ],
   "source": [
    "for col in [\"BUDGET\", \"GLOBAL_GROSS\"]:\n",
    "    non_nulls = imdb[col].notnull()\n",
    "    nr_non_nulls = non_nulls.sum()\n",
    "    nr_non_USD = (imdb.loc[non_nulls, col].str.startswith(\"USD\") == False).sum()\n",
    "    non_USD_pct = round(100 * nr_non_USD / nr_non_nulls, 1)\n",
    "    print(\"Non-USD {} values: {} out of {} non-null values. ({}%)\".format(col, nr_non_USD, nr_non_nulls, non_USD_pct))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c769d7-0599-4934-b73a-ab62e8c7cc85",
   "metadata": {},
   "source": [
    "The number of non-USD global grosses is insignificant compared to the total number of non-null global grosses. This isn't quite the case for non-USD budgets, which constitute 30% of all the available budgets, but I think it's better to give up on that 30% than to go on a wild goose chase looking for all sorts of ancient CPI records. Let's set all non-USD budgets and global grosses to `nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b4446d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null BUDGET values increased by: 7108 (Should be 7108)\n",
      "Null GLOBAL_GROSS values increased by: 61 (Should be 61)\n"
     ]
    }
   ],
   "source": [
    "from numpy import nan\n",
    "\n",
    "for col in [\"BUDGET\", \"GLOBAL_GROSS\"]:\n",
    "    nulls_before = imdb[col].isna().sum()\n",
    "    non_USD = imdb[col].str.startswith(\"USD\") == False\n",
    "    non_USD_count = non_USD.sum()\n",
    "    imdb.loc[non_USD, col] = nan    \n",
    "    nulls_after = imdb[col].isna().sum()\n",
    "\n",
    "    print(\"Null {} values increased by: {} (Should be {})\".format(col, nulls_after - nulls_before, non_USD_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9232c33d",
   "metadata": {},
   "source": [
    "At this point, the only currency in both `BUDGET` and `GLOBAL_GROSS` should be `USD` (or `nan`, in case of null values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0da28b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'USD']\n"
     ]
    }
   ],
   "source": [
    "print_all_currencies()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b67f91e",
   "metadata": {},
   "source": [
    "#### Currency consistency check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44593c82-cd47-47ae-9d8d-9dc86b17b9a4",
   "metadata": {},
   "source": [
    "While it's perfectly normal for worldwide grosses to be expressed in USD, regardless of the movie's country of origin, that would be a little suspect for budgets. All the budgets we have left now were expressed in USD to begin with, so we can check whether the USA is at least among the countries of origin for each of the movies corresponding to these budgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cb0f9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3203"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_currency_mismatch_count = imdb.loc[(imdb[\"BUDGET\"].notnull()) & (imdb[\"COUNTRY\"].str.contains(\"USA\") == False)].shape[0]\n",
    "country_currency_mismatch_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdbae11",
   "metadata": {},
   "source": [
    "For the 3203 movies above, there's a chance that the reported budget is wrong, because the currency doesn't match the country of origin. In our case, 3203 budgets is a lot of data to throw away, but cheking and correcting them manually would be a time sink. If they're wrong, they'd skew the analysis, so it's best to `nan` these too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "804d44cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null BUDGET values increased by: 3203 (Should be 3203)\n"
     ]
    }
   ],
   "source": [
    "null_budgets_before = imdb[\"BUDGET\"].isna().sum()\n",
    "imdb.loc[(imdb[\"BUDGET\"].isna() == False) & (imdb[\"COUNTRY\"].str.contains(\"USA\") == False), \"BUDGET\"] = nan\n",
    "null_budgets_after = imdb[\"BUDGET\"].isna().sum()\n",
    "\n",
    "print(\"Null BUDGET values increased by: {} (Should be {})\".format(null_budgets_after - null_budgets_before, country_currency_mismatch_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd3b5a8",
   "metadata": {},
   "source": [
    "At this point, the string `USD` may as well be removed from both the `BUDGET` and `GLOBAL_GROSS` columns. The columns themselves can be turned into `float` and renamed to `BUDGET_USD` and `GLOBAL_GROSS_USD` for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4bf6b377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 85855 entries, 0 to 85854\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   ID                85855 non-null  object \n",
      " 1   TITLE             85855 non-null  object \n",
      " 2   RELEASE_YEAR      85855 non-null  int32  \n",
      " 3   GENRE             85855 non-null  object \n",
      " 4   LENGTH_MIN        85855 non-null  int64  \n",
      " 5   COUNTRY           85855 non-null  object \n",
      " 6   AVG_SCORE         85855 non-null  float64\n",
      " 7   VOTES             85855 non-null  int64  \n",
      " 8   BUDGET_USD        13399 non-null  float64\n",
      " 9   GLOBAL_GROSS_USD  30955 non-null  float64\n",
      "dtypes: float64(3), int32(1), int64(2), object(4)\n",
      "memory usage: 6.2+ MB\n"
     ]
    }
   ],
   "source": [
    "imdb[\"BUDGET\"] = imdb[\"BUDGET\"].str.replace(r\"USD \", \"\", regex = False).astype(float)\n",
    "imdb[\"GLOBAL_GROSS\"] = imdb[\"GLOBAL_GROSS\"].str.replace(r\"USD \", \"\", regex = False).astype(float)\n",
    "\n",
    "imdb.rename(columns = {\"BUDGET\":\"BUDGET_USD\",\"GLOBAL_GROSS\":\"GLOBAL_GROSS_USD\"}, inplace = True)\n",
    "imdb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bcea8d",
   "metadata": {},
   "source": [
    "#### Currency conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2922a2d-02ae-4c91-a08e-1af1a7f53bab",
   "metadata": {},
   "source": [
    "At this point, all that's left is adjusting budgets and grosses for inflation. To do that, we only need historical CPI values for the USD, available in the `hist_CPIs.csv` file mentioned in the introduction. Unfortunately, historical CPIs before 1913 aren't available, so, for movies released before 1913, adjusting budget or gross values for inflation won't be possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b3d382c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies released before 1913: 12\n"
     ]
    }
   ],
   "source": [
    "print(\"Movies released before 1913: {}\".format(len(imdb.query(\"RELEASE_YEAR < 1913\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b076f3d4",
   "metadata": {},
   "source": [
    "That's not a lot of entries, so we can exclude them from currency analyses and replace their budget and grosses with nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e7eb983",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb.loc[imdb[\"RELEASE_YEAR\"] < 1913, [\"BUDGET_USD\", \"GLOBAL_GROSS_USD\"]] = nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33b110e",
   "metadata": {},
   "source": [
    "The rest of the budget and gross values can all be adjusted for inflation. To proceed with the conversion, we need to extract the historical CPI values and organise them in a convenient format. We'll use a dictionary, `hist_CPIs`, with `(year, CPI-of-year)` key-value pairs. To create it, we need a list of release years of movies for which the budget and/or global gross are available. We can then associate each of these years to its CPI. Let's first load the CSV with historical CPI values and have a look at it. It only has two columns, one of which is convenient to set as the `index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14320cec-8ba4-4e63-955c-04d71707463d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USD_CPI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      USD_CPI\n",
       "YEAR         \n",
       "1913      9.9\n",
       "1914     10.0\n",
       "1915     10.1\n",
       "1916     10.9\n",
       "1917     12.8"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_CPIs_file = pd.read_csv(\"hist_CPIs.csv\", header = 0, index_col = \"YEAR\")\n",
    "hist_CPIs_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1b8c05-563e-4f8f-bfc2-9308b621f2b5",
   "metadata": {},
   "source": [
    "Now we make a list of available release years, look them up in the CPI file, and use the values to populate our year-CPI dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60a5d804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each movie with a known budget or global gross, extract the release year.\n",
    "non_na_budget_gross_mask = (imdb[\"BUDGET_USD\"].notnull() | imdb[\"GLOBAL_GROSS_USD\"].notnull())\n",
    "release_years = list(imdb.loc[non_na_budget_gross_mask, \"RELEASE_YEAR\"].unique())\n",
    "\n",
    "hist_CPIs = {year : hist_CPIs_file.at[year, \"USD_CPI\"] for year in release_years}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85ebe0a",
   "metadata": {},
   "source": [
    "2021 wasn't among the available release years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46a38d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(release_years)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb12547",
   "metadata": {},
   "source": [
    "so let's add it manually, because the 2021 CPI is kind of indispensable to adjust for inflation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff3de126",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_CPIs[2021] = hist_CPIs_file.at[2021, \"USD_CPI\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caff5dc2",
   "metadata": {},
   "source": [
    "Now budgets and global grosses can be converted to 2021 USD dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2e095a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_for_inflation(series):\n",
    "    \"\"\"Adjusts USD amounts for inflation, converting them to 2021 USD, rounded to nearest integer.\n",
    "    `series` is a series with two rows; the first one is the (movie release) year we're converting from, \n",
    "    while the second one is the amount of money to be converted.\n",
    "    \"\"\"\n",
    "    release_year = series.iloc[0] \n",
    "    amount = series.iloc[1] \n",
    "    \n",
    "    USD2021 = round((hist_CPIs[2021] / hist_CPIs[release_year]) * amount)\n",
    "    return USD2021\n",
    "\n",
    "imdb[\"BUDGET_ADJUSTED\"] = imdb.loc[imdb[\"BUDGET_USD\"].isnull() == False, [\"RELEASE_YEAR\", \"BUDGET_USD\"]].apply(adjust_for_inflation, axis = 1)\n",
    "imdb[\"GROSS_ADJUSTED\"] = imdb.loc[imdb[\"GLOBAL_GROSS_USD\"].isnull() == False, [\"RELEASE_YEAR\", \"GLOBAL_GROSS_USD\"]].apply(adjust_for_inflation, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebb98f7",
   "metadata": {},
   "source": [
    "Now we only have to check that the adjusted values make sense before swapping them with the originals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ee1fb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RELEASE_YEAR</th>\n",
       "      <th>BUDGET_USD</th>\n",
       "      <th>BUDGET_ADJUSTED</th>\n",
       "      <th>GLOBAL_GROSS_USD</th>\n",
       "      <th>GROSS_ADJUSTED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>85855.000000</td>\n",
       "      <td>1.339700e+04</td>\n",
       "      <td>1.339700e+04</td>\n",
       "      <td>3.095500e+04</td>\n",
       "      <td>3.095500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1993.500891</td>\n",
       "      <td>1.630055e+07</td>\n",
       "      <td>2.621104e+07</td>\n",
       "      <td>2.252786e+07</td>\n",
       "      <td>3.398148e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.216420</td>\n",
       "      <td>3.141170e+07</td>\n",
       "      <td>4.132958e+07</td>\n",
       "      <td>8.881907e+07</td>\n",
       "      <td>1.372938e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1894.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1979.000000</td>\n",
       "      <td>6.621410e+05</td>\n",
       "      <td>1.576074e+06</td>\n",
       "      <td>1.149520e+05</td>\n",
       "      <td>1.587655e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2003.000000</td>\n",
       "      <td>3.346500e+06</td>\n",
       "      <td>1.031637e+07</td>\n",
       "      <td>1.108231e+06</td>\n",
       "      <td>1.483916e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2013.000000</td>\n",
       "      <td>1.800000e+07</td>\n",
       "      <td>3.242533e+07</td>\n",
       "      <td>8.299774e+06</td>\n",
       "      <td>1.201032e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>3.560000e+08</td>\n",
       "      <td>3.927641e+08</td>\n",
       "      <td>2.797801e+09</td>\n",
       "      <td>7.856006e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RELEASE_YEAR    BUDGET_USD  BUDGET_ADJUSTED  GLOBAL_GROSS_USD  \\\n",
       "count  85855.000000  1.339700e+04     1.339700e+04      3.095500e+04   \n",
       "mean    1993.500891  1.630055e+07     2.621104e+07      2.252786e+07   \n",
       "std       24.216420  3.141170e+07     4.132958e+07      8.881907e+07   \n",
       "min     1894.000000  0.000000e+00     0.000000e+00      1.000000e+00   \n",
       "25%     1979.000000  6.621410e+05     1.576074e+06      1.149520e+05   \n",
       "50%     2003.000000  3.346500e+06     1.031637e+07      1.108231e+06   \n",
       "75%     2013.000000  1.800000e+07     3.242533e+07      8.299774e+06   \n",
       "max     2020.000000  3.560000e+08     3.927641e+08      2.797801e+09   \n",
       "\n",
       "       GROSS_ADJUSTED  \n",
       "count    3.095500e+04  \n",
       "mean     3.398148e+07  \n",
       "std      1.372938e+08  \n",
       "min      3.000000e+00  \n",
       "25%      1.587655e+05  \n",
       "50%      1.483916e+06  \n",
       "75%      1.201032e+07  \n",
       "max      7.856006e+09  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_check =imdb[[\"TITLE\", \"RELEASE_YEAR\", \"BUDGET_USD\", \"BUDGET_ADJUSTED\", \"GLOBAL_GROSS_USD\", \"GROSS_ADJUSTED\"]]\n",
    "adjusted_check.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1301680b",
   "metadata": {},
   "source": [
    "The adjusted values are comparable in terms of order of magnitude, so there *shouldn't* be anything weird going on with the budgets, and similarly with the grosses. To double-check that, we can use [this IMDB list](https://www.imdb.com/list/ls026442468/) of highest-grossing blockbusters adjusted for inflation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9698c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>GLOBAL_GROSS_USD</th>\n",
       "      <th>GROSS_ADJUSTED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>Gone with the Wind</td>\n",
       "      <td>4.023526e+08</td>\n",
       "      <td>7.856006e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4104</th>\n",
       "      <td>Bambi</td>\n",
       "      <td>2.674472e+08</td>\n",
       "      <td>4.453077e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31086</th>\n",
       "      <td>Titanic</td>\n",
       "      <td>2.195170e+09</td>\n",
       "      <td>3.711957e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49415</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>2.790439e+09</td>\n",
       "      <td>3.530653e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>Snow White and the Seven Dwarfs</td>\n",
       "      <td>1.849255e+08</td>\n",
       "      <td>3.485332e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18216</th>\n",
       "      <td>Star Wars</td>\n",
       "      <td>7.757689e+08</td>\n",
       "      <td>3.474318e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73865</th>\n",
       "      <td>Avengers: Endgame</td>\n",
       "      <td>2.797801e+09</td>\n",
       "      <td>2.969586e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16015</th>\n",
       "      <td>The Exorcist</td>\n",
       "      <td>4.413061e+08</td>\n",
       "      <td>2.697534e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17068</th>\n",
       "      <td>Jaws</td>\n",
       "      <td>4.719614e+08</td>\n",
       "      <td>2.380861e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67523</th>\n",
       "      <td>Star Wars: Episode VII - The Force Awakens</td>\n",
       "      <td>2.068224e+09</td>\n",
       "      <td>2.368422e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            TITLE  GLOBAL_GROSS_USD  \\\n",
       "3266                           Gone with the Wind      4.023526e+08   \n",
       "4104                                        Bambi      2.674472e+08   \n",
       "31086                                     Titanic      2.195170e+09   \n",
       "49415                                      Avatar      2.790439e+09   \n",
       "2827              Snow White and the Seven Dwarfs      1.849255e+08   \n",
       "18216                                   Star Wars      7.757689e+08   \n",
       "73865                           Avengers: Endgame      2.797801e+09   \n",
       "16015                                The Exorcist      4.413061e+08   \n",
       "17068                                        Jaws      4.719614e+08   \n",
       "67523  Star Wars: Episode VII - The Force Awakens      2.068224e+09   \n",
       "\n",
       "       GROSS_ADJUSTED  \n",
       "3266     7.856006e+09  \n",
       "4104     4.453077e+09  \n",
       "31086    3.711957e+09  \n",
       "49415    3.530653e+09  \n",
       "2827     3.485332e+09  \n",
       "18216    3.474318e+09  \n",
       "73865    2.969586e+09  \n",
       "16015    2.697534e+09  \n",
       "17068    2.380861e+09  \n",
       "67523    2.368422e+09  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_check[[\"TITLE\", \"GLOBAL_GROSS_USD\", \"GROSS_ADJUSTED\"]].sort_values(\"GROSS_ADJUSTED\", axis = 0, ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b70e84",
   "metadata": {},
   "source": [
    "The highest gross value is *Gone with the Wind*. According to the very IMDB page I linked above, adjusting for inflation for such old movies is very hard. *Gone with the Wind* is first-place on their list too, but their inflation-adjusted gross is around 3.75 billion, far less than our 7.8 billion. However, that IMDB page shows two different values for the gross:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c54900a-33c6-466e-b2ae-95c14ca5719b",
   "metadata": {},
   "source": [
    "![](gww.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081408a6-4835-49dc-90e9-e6eeed2d043d",
   "metadata": {},
   "source": [
    "In the case of *Gone with the Wind*, the  `Gross` value (highlighted in green) is 198.68 million USD. There's another suspect value, `Real Worldwide Box Office`, which we'll get to in a minute, but for now, let's focus on the `Gross` value. Using the inflation-adjusting formula we've used so far, this value becomes very close to the the `Adjusted` value in the picture above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e194114d-fb16-46d4-9a01-f93941db3527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3879262734\n"
     ]
    }
   ],
   "source": [
    "gww_test = adjust_for_inflation(pd.Series([1939, 198680000]))\n",
    "print(gww_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69953aa2-6368-40d8-a93f-3b2f5cb50569",
   "metadata": {},
   "source": [
    "That is, about 3.87 billion USD, while the `Adjusted` value in the screenshot is about 3.75.  Other movies on that page show similar patterns,  which suggests that the `Adjusted` amounts on the IMDB page are calculated from the `Gross` value, probably using a very similar formula to what we used. The `GLOBAL_GROSS_USD` column in our dataset doesn't contain the same values as this `Gross` field on the page, but rather the `Real World Wide Box Office` values; for example, in the case of *Gone with the Wind*, `GLOBAL_GROSS_USD` is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8acebe1f-dfdc-4d38-b689-a2a80fa879e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TITLE               Gone with the Wind\n",
       "GLOBAL_GROSS_USD           402352579.0\n",
       "Name: 3266, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.loc[3266, [\"TITLE\", \"GLOBAL_GROSS_USD\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ae884e-2548-44e4-9de3-f07b528d837f",
   "metadata": {},
   "source": [
    "That is, about 402.3 million USD, as shown in the blue box above. Again, this is true of other movies as well on that page, and while it's hard to tell what's the difference between `Gross` and `Real Worldwide Box Office`, it's clear that in our dataset we have the latter, and that our formula is accurate enough, as feeding it `Gross` values from the IMDB page yields values very close to the `Adjusted` values on the same page. For the scope of this project, this level of accuracy is sufficient, so we can replace our `BUDGET_USD` and `GLOBAL_GROSS_USD` columns with their adjusted counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c80d8033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of the non-adjusted columns.\n",
    "imdb.drop(columns = [\"BUDGET_USD\", \"GLOBAL_GROSS_USD\"], inplace = True)\n",
    "\n",
    "# Rename the adjusted columns like the columns we just dropped.\n",
    "imdb.rename(columns = {\"BUDGET_ADJUSTED\": \"BUDGET_USD\", \"GROSS_ADJUSTED\": \"GLOBAL_GROSS_USD\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfcb6de",
   "metadata": {},
   "source": [
    "## Second dataset: `imdb_ratings`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cd1b9b-8479-4839-a4e6-bb824e10f845",
   "metadata": {},
   "source": [
    "A significant part of the main project is about movie scores, and for that we'll needed data from the `imdb_ratings.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42f02d9d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 85855 entries, 0 to 85854\n",
      "Data columns (total 49 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   imdb_title_id              85855 non-null  object \n",
      " 1   weighted_average_vote      85855 non-null  float64\n",
      " 2   total_votes                85855 non-null  int64  \n",
      " 3   mean_vote                  85855 non-null  float64\n",
      " 4   median_vote                85855 non-null  float64\n",
      " 5   votes_10                   85855 non-null  int64  \n",
      " 6   votes_9                    85855 non-null  int64  \n",
      " 7   votes_8                    85855 non-null  int64  \n",
      " 8   votes_7                    85855 non-null  int64  \n",
      " 9   votes_6                    85855 non-null  int64  \n",
      " 10  votes_5                    85855 non-null  int64  \n",
      " 11  votes_4                    85855 non-null  int64  \n",
      " 12  votes_3                    85855 non-null  int64  \n",
      " 13  votes_2                    85855 non-null  int64  \n",
      " 14  votes_1                    85855 non-null  int64  \n",
      " 15  allgenders_0age_avg_vote   33359 non-null  float64\n",
      " 16  allgenders_0age_votes      33359 non-null  float64\n",
      " 17  allgenders_18age_avg_vote  85149 non-null  float64\n",
      " 18  allgenders_18age_votes     85149 non-null  float64\n",
      " 19  allgenders_30age_avg_vote  85845 non-null  float64\n",
      " 20  allgenders_30age_votes     85845 non-null  float64\n",
      " 21  allgenders_45age_avg_vote  85775 non-null  float64\n",
      " 22  allgenders_45age_votes     85775 non-null  float64\n",
      " 23  males_allages_avg_vote     85854 non-null  float64\n",
      " 24  males_allages_votes        85854 non-null  float64\n",
      " 25  males_0age_avg_vote        27411 non-null  float64\n",
      " 26  males_0age_votes           27411 non-null  float64\n",
      " 27  males_18age_avg_vote       84390 non-null  float64\n",
      " 28  males_18age_votes          84390 non-null  float64\n",
      " 29  males_30age_avg_vote       85843 non-null  float64\n",
      " 30  males_30age_votes          85843 non-null  float64\n",
      " 31  males_45age_avg_vote       85754 non-null  float64\n",
      " 32  males_45age_votes          85754 non-null  float64\n",
      " 33  females_allages_avg_vote   85774 non-null  float64\n",
      " 34  females_allages_votes      85774 non-null  float64\n",
      " 35  females_0age_avg_vote      22117 non-null  float64\n",
      " 36  females_0age_votes         22117 non-null  float64\n",
      " 37  females_18age_avg_vote     79334 non-null  float64\n",
      " 38  females_18age_votes        79334 non-null  float64\n",
      " 39  females_30age_avg_vote     84911 non-null  float64\n",
      " 40  females_30age_votes        84911 non-null  float64\n",
      " 41  females_45age_avg_vote     83057 non-null  float64\n",
      " 42  females_45age_votes        83057 non-null  float64\n",
      " 43  top1000_voters_rating      85176 non-null  float64\n",
      " 44  top1000_voters_votes       85176 non-null  float64\n",
      " 45  us_voters_rating           85646 non-null  float64\n",
      " 46  us_voters_votes            85646 non-null  float64\n",
      " 47  non_us_voters_rating       85854 non-null  float64\n",
      " 48  non_us_voters_votes        85854 non-null  float64\n",
      "dtypes: float64(37), int64(11), object(1)\n",
      "memory usage: 32.1+ MB\n"
     ]
    }
   ],
   "source": [
    "imdb_ratings = pd.read_csv(\"imdb_ratings.csv\", header = 0)\n",
    "imdb_ratings.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d91eb7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Just to be picky, let's make extra-sure that the two datasets have the same IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "44507e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_ratings[\"imdb_title_id\"].equals(imdb[\"ID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f462e5eb",
   "metadata": {},
   "source": [
    "That was expected, but great news nonetheless because it's the obvious column of choice to eventually merge the two datasets. Therefore, it makes sense to rename it too as `ID`. However, there'll be more renaming to do, so rather than doing it one column at a time, let's just keep track of what needs renaming to what, and then we'll call `rename` only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "766388ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = {\"imdb_title_id\": \"ID\"} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399acb59",
   "metadata": {},
   "source": [
    "#### Identifying and dropping unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a79119d-9c7c-402e-9cd3-d83e1e0e4b4d",
   "metadata": {},
   "source": [
    "There are columns that are likely duplicates: `total_votes`, which is probably the same as `VOTES` from the `imdb` dataset, and `weighted_average_vote`, which is probably the same as `AVG_SCORE` again from `imdb`. Before we delete them, let's make sure that they are indeed redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e6de897c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does VOTES contain the same data as total_votes?  True\n",
      "Are votes in AVG_SCORE the same as those in weighted_average_vote? True\n"
     ]
    }
   ],
   "source": [
    "# Check the votes columns.\n",
    "imdb_votes = imdb[\"VOTES\"]\n",
    "total_votes = imdb_ratings[\"total_votes\"]\n",
    "print('Does VOTES contain the same data as total_votes? ', imdb_votes.equals(total_votes))\n",
    "\n",
    "# Check the score columns.\n",
    "avg_from_imdb = imdb[\"AVG_SCORE\"]\n",
    "wavg_from_ratings = imdb_ratings[\"weighted_average_vote\"]\n",
    "\n",
    "print(\"Are votes in AVG_SCORE the same as those in weighted_average_vote?\", avg_from_imdb.equals(wavg_from_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26be02c-144b-44ce-aeb9-ba6793280fd9",
   "metadata": {},
   "source": [
    "As expected, both `total_votes`  and `weighted_average_vote` can be eliminated. For clarity, we'll also rename `AVG_SCORE` in the first dataset to `WAVG_SCORE`, to remind ourselves that it is some kind of weighted average. (According to IMDB, this column is actually calculated according to some [secret sauce](https://help.imdb.com/article/imdb/track-movies-tv/ratings-faq/G67Y87TFYYP6TWAV#) to ensure vote reliability.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "330ea104-3b4f-461e-9ddd-d16ccd82e90b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imdb_ratings.drop(columns = [\"total_votes\", \"weighted_average_vote\"], inplace = True)\n",
    "imdb.rename(columns = {\"AVG_SCORE\": \"WAVG_SCORE\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbfedcc-1576-44e5-8ea9-f9836559b808",
   "metadata": {},
   "source": [
    "The `mean_vote` column, instead is not the same as the `WAVG_SCORE` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc62ac51-de37-485b-8412-009a39d2c598",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are votes in WAVG_SCORE the same as those in mean_vote? False\n"
     ]
    }
   ],
   "source": [
    "mean_from_ratings = imdb_ratings[\"mean_vote\"]\n",
    "print(\"Are votes in WAVG_SCORE the same as those in mean_vote?\", mean_from_ratings.equals(imdb[\"WAVG_SCORE\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc7f898",
   "metadata": {},
   "source": [
    "`mean_vote` is probably just a simple average and therefore (supposedly) less reliable or interesting than IMDB's secret sauce average, but before we drop it, let's make sure that it is indeed just a simple average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b95af18e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    85805\n",
       "True        50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_mean(breakdown):    \n",
    "    \"\"\"Calculates a simple arithmetic mean of a movie's score from its score breakdown.\n",
    "    The score breakdown contains the number of votes each of the 10 possible scores has received.\n",
    "    \n",
    "    `breakdown` is a series representing a movie's score breakdown, indexed from `votes_10` to `votes_1`\n",
    "    \"\"\"    \n",
    "    total_votes = breakdown.sum()\n",
    "    scores = [10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n",
    "    \n",
    "    # Multiply `votes_10` by 10, `votes_9` by 9, etc. Then sum them together and divide by total votes.\n",
    "    mean_score = (breakdown * scores).sum() / total_votes\n",
    "    mean_score = mean_score.round(1)\n",
    "        \n",
    "    return mean_score\n",
    "\n",
    "# Extract a sub dataframe containing only how many votes each score has received for each movie.\n",
    "score_breakdown = imdb_ratings.loc[: , \"votes_10\" : \"votes_1\"]\n",
    "\n",
    "# Calculate the mean score of each movie.\n",
    "calculated_mean_score = score_breakdown.apply(calculate_mean, axis = 1)\n",
    "\n",
    "# See if `calculated_mean_score` and the `mean_vote` column are different.\n",
    "mismatches = calculated_mean_score != imdb_ratings[\"mean_vote\"]\n",
    "mismatches.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917af460",
   "metadata": {},
   "source": [
    "In the vast majority of cases, the calculated mean score is the same as the corresponding values in the `mean_vote` column. This alone is proof enough that `mean_vote` is just a simple average, but out of curiosity, let's check how different those 50 mismatches are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0b8fe7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min error: -2.85714285714286\n",
      "Max error: 2.85714285714286\n",
      "Mean error: 0.26802026681855945\n"
     ]
    }
   ],
   "source": [
    "mean_vote_mismatch = imdb_ratings.loc[mismatches, \"mean_vote\"] # The 50 `mean_vote` values that differ from the calculated ones.\n",
    "calculated_score_mismatch = calculated_mean_score[mismatches]  # The 50 calculated mean scores that differ from the 50 above.\n",
    "\n",
    "mismatch_percent = ((calculated_score_mismatch - mean_vote_mismatch) / mean_vote_mismatch) * 100\n",
    "print(\"Min error: {}\\nMax error: {}\\nMean error: {}\".format(mismatch_percent.min(), mismatch_percent.max(), mismatch_percent.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc625485",
   "metadata": {},
   "source": [
    "On average, the only 50 mismatching scores were about 0.26% larger than the original values in `mean_vote`. This is probably due to floating-point ops approximations, so it's safe to say that `mean_vote` is indeed a simple arithmetic mean, and so we can drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ffbede88",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_ratings.drop(columns = [\"mean_vote\"], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73e8cf0-a844-497d-a150-8fa96d846a71",
   "metadata": {},
   "source": [
    "As a matter of fact, in the main project we won't be needing the `median_vote` column either, nor any of the `votes_10`, `votes_9`, etc., columns (which contain the number of voters that gave a specific score to a movie). We also won't need any of the columns dealing with top voters, nor with voter location, so we can drop them too. In the main project, we won't be needing any of the `allgenders` columns either, but for the moment, we'll keep the `allgenders` votes columns and drop the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0fa5b1f2-6ea6-4919-9ab3-23b813ebae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ([\"median_vote\"] + \n",
    "                [\"votes_{}\".format(i) for i in range(1, 11)] + \n",
    "                [\"top1000_voters_rating\", \"top1000_voters_votes\", \"us_voters_rating\", \"non_us_voters_rating\", \"us_voters_votes\", \"non_us_voters_votes\"] +\n",
    "                [\"allgenders_{}age_avg_vote\".format(i) for i in [0, 18, 30, 45]])\n",
    "imdb_ratings.drop(columns = cols_to_drop, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2619c073-7fe8-4492-ac65-cc3016aebac1",
   "metadata": {},
   "source": [
    "Now we can rename columns with the same style used in the previous file. Note that, as far as we know, the only secret-sauce weighted average is the final score that IMDB gives to each movie, stored in the `WAVG_SCORE` column. All other averages, such as the average score of all male or female voters, for example, are likely just normal averages, so their new names will contain the abbreviation `AVG`, not `WAVG`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "78f8228a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 85855 entries, 0 to 85854\n",
      "Data columns (total 25 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   ID                  85855 non-null  object \n",
      " 1   MF_017_VOTES        33359 non-null  float64\n",
      " 2   MF_1829_VOTES       85149 non-null  float64\n",
      " 3   MF_3044_VOTES       85845 non-null  float64\n",
      " 4   MF_45PLUS_VOTES     85775 non-null  float64\n",
      " 5   M_AVG_SCORE         85854 non-null  float64\n",
      " 6   M_VOTES             85854 non-null  float64\n",
      " 7   M_017_AVG_SCORE     27411 non-null  float64\n",
      " 8   M_017_VOTES         27411 non-null  float64\n",
      " 9   M_1829_AVG_SCORE    84390 non-null  float64\n",
      " 10  M_1829_VOTES        84390 non-null  float64\n",
      " 11  M_3044_AVG_SCORE    85843 non-null  float64\n",
      " 12  M_3044_VOTES        85843 non-null  float64\n",
      " 13  M_45PLUS_AVG_SCORE  85754 non-null  float64\n",
      " 14  M_45PLUS_VOTES      85754 non-null  float64\n",
      " 15  F_AVG_SCORE         85774 non-null  float64\n",
      " 16  F_VOTES             85774 non-null  float64\n",
      " 17  F_017_AVG_SCORE     22117 non-null  float64\n",
      " 18  F_017_VOTES         22117 non-null  float64\n",
      " 19  F_1829_AVG_SCORE    79334 non-null  float64\n",
      " 20  F_1829_VOTES        79334 non-null  float64\n",
      " 21  F_3044_AVG_SCORE    84911 non-null  float64\n",
      " 22  F_3044_VOTES        84911 non-null  float64\n",
      " 23  F_45PLUS_AVG_SCORE  83057 non-null  float64\n",
      " 24  F_45PLUS_VOTES      83057 non-null  float64\n",
      "dtypes: float64(24), object(1)\n",
      "memory usage: 16.4+ MB\n"
     ]
    }
   ],
   "source": [
    "def update_name(old_name):\n",
    "    \"\"\"Updates a column name according to predefined criteria.\n",
    "    `old_name` is a string containing the name to update.\n",
    "    \"\"\"    \n",
    "    replacements = {\"_allages\": \"\",\n",
    "                    \"allgenders\": \"MF\",\n",
    "                    \"females\": \"F\",\n",
    "                    \"males\": \"M\",                                        \n",
    "                    \"18age\": \"1829\",\n",
    "                    \"30age\": \"3044\",\n",
    "                    \"45age\": \"45PLUS\",\n",
    "                    \"0age\": \"017\",                    \n",
    "                    \"avg_vote\": \"AVG_SCORE\"}    \n",
    "    \n",
    "    new_name = old_name\n",
    "    for r in replacements:\n",
    "        new_name = new_name.replace(r, replacements[r])        \n",
    "    return new_name.upper()\n",
    "\n",
    "\n",
    "old_columns_1_to_end = imdb_ratings.columns[1:]\n",
    "\n",
    "# Update all old column names.\n",
    "for old_name in old_columns_1_to_end:\n",
    "    new_column_names[old_name] = update_name(old_name)\n",
    "\n",
    "imdb_ratings.rename(columns = new_column_names, inplace = True)\n",
    "imdb_ratings.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b49181f-3e07-434b-b596-136798fbedcf",
   "metadata": {},
   "source": [
    "#### Handling nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e4361e-66f3-42be-a6b9-d2724c5d05de",
   "metadata": {},
   "source": [
    "There are quite a few columns with nulls to handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "78ac7a63-39f1-4c71-8b7a-5928dfcef4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 85855 entries, 0 to 85854\n",
      "Data columns (total 24 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   MF_017_VOTES        33359 non-null  float64\n",
      " 1   MF_1829_VOTES       85149 non-null  float64\n",
      " 2   MF_3044_VOTES       85845 non-null  float64\n",
      " 3   MF_45PLUS_VOTES     85775 non-null  float64\n",
      " 4   M_AVG_SCORE         85854 non-null  float64\n",
      " 5   M_VOTES             85854 non-null  float64\n",
      " 6   M_017_AVG_SCORE     27411 non-null  float64\n",
      " 7   M_017_VOTES         27411 non-null  float64\n",
      " 8   M_1829_AVG_SCORE    84390 non-null  float64\n",
      " 9   M_1829_VOTES        84390 non-null  float64\n",
      " 10  M_3044_AVG_SCORE    85843 non-null  float64\n",
      " 11  M_3044_VOTES        85843 non-null  float64\n",
      " 12  M_45PLUS_AVG_SCORE  85754 non-null  float64\n",
      " 13  M_45PLUS_VOTES      85754 non-null  float64\n",
      " 14  F_AVG_SCORE         85774 non-null  float64\n",
      " 15  F_VOTES             85774 non-null  float64\n",
      " 16  F_017_AVG_SCORE     22117 non-null  float64\n",
      " 17  F_017_VOTES         22117 non-null  float64\n",
      " 18  F_1829_AVG_SCORE    79334 non-null  float64\n",
      " 19  F_1829_VOTES        79334 non-null  float64\n",
      " 20  F_3044_AVG_SCORE    84911 non-null  float64\n",
      " 21  F_3044_VOTES        84911 non-null  float64\n",
      " 22  F_45PLUS_AVG_SCORE  83057 non-null  float64\n",
      " 23  F_45PLUS_VOTES      83057 non-null  float64\n",
      "dtypes: float64(24)\n",
      "memory usage: 15.7 MB\n"
     ]
    }
   ],
   "source": [
    "cols_with_nulls = imdb_ratings.columns[imdb_ratings.isna().any()]\n",
    "imdb_ratings[cols_with_nulls].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcfcebf-0dbb-4ffd-9067-eed51c944484",
   "metadata": {},
   "source": [
    "The first four columns will eventually be dropped, so we don't really care about their nulls. As for the others, seeing as how they all have pairwise the same amount of non-nulls (and, hence, of nulls), it seems reasonable that pairs of columns have nulls in the exact same places. So for example, `F_3044_AVG_SCORE` should have nulls exactly where `F_3044_VOTES` does. (This makes sense, because if we have no votes from females between the ages of 30 and 44, we certainly don't have an average score for them either.) Each column pairs up with the one immediately after it, so checking whether this guess is correct is fairly easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "14c3919a-8a67-491c-91e6-98c2c564cc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No unpaired nulls found across any pairs of columns.\n"
     ]
    }
   ],
   "source": [
    "exit_message = \"No unpaired nulls found across any pairs of columns.\"\n",
    "\n",
    "for i in range(4, len(cols_with_nulls), 2):    \n",
    "    col1 = cols_with_nulls[i]\n",
    "    col2 = cols_with_nulls[i + 1]\n",
    "    # Find dataset entries where EITHER col1 OR col2 is null, but not both.\n",
    "    unpaired_nulls = (imdb_ratings[col1].isna() ^ imdb_ratings[col2].isna()).sum()    \n",
    "    if unpaired_nulls > 0:\n",
    "        exit_message = \"\"\n",
    "        print(\"Column {} and {} have {} unpaired nulls.\".format(col1, col2, unpaired_nulls))\n",
    "print(exit_message)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c245779-4e61-4919-90a3-1c0b31b4977d",
   "metadata": {},
   "source": [
    "Any null values in these columns obviously mean that the specific category represented by the column did not cast any vote for some movies. For example, it may well be that some movies weren't scored by any males between the ages of 0 and 17. However, it should still be the case that the sum of all votes from males and females add up to the total of all votes for any given movie, for example. If these sums are *smaller* than the relevant total, it's no big deal: some of the votes came from users whose sex or age was unknown. If these sums are *bigger* than the total, something quite literally doesn't add up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "97d86c7d-397b-4f38-9b8c-cad6cf7d26ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Smaller    62743\n",
       "Equal      23112\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def determine_mismatch(difference):\n",
    "    \"\"\"Takes in a number and determines its sign or if it's zero. The number represents the difference between the sum \n",
    "       of different Series and their expected total. Used to determine if the sum adds up correctly or if it's smaller or larger than it should.\n",
    "       `difference` is the number whose sign must be checked.\"\"\"\n",
    "    if difference < 0: return \"Smaller\"\n",
    "    if difference > 0: return \"Larger\"\n",
    "    return \"Equal\"\n",
    "\n",
    "# Age&sex brackets: Is M plus F for each age bracket equal to the total of the age bracket?\n",
    "for bracket in [\"017\", \"1829\", \"3044\", \"45PLUS\"]:\n",
    "    m_plus_f = imdb_ratings[\"M_{}_VOTES\".format(bracket)] + imdb_ratings[\"F_{}_VOTES\".format(bracket)]\n",
    "    bracket_mismatch_type = (m_plus_f - imdb_ratings[\"MF_{}_VOTES\".format(bracket)]).apply(determine_mismatch)\n",
    "bracket_mismatch_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797015f1-a8af-4046-9839-216238a8cd9c",
   "metadata": {},
   "source": [
    "We don't have any case where the sum exceeds the total, so, as said, this only means that for some movies, the age or sex of the voter wasn't known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3f6c39de-5548-4ca0-a148-398b2a96357e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal      58784\n",
      "Smaller    27071\n",
      "dtype: int64\n",
      "Equal      65766\n",
      "Smaller    20089\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Sex: does the sum of age brackets, for each sex, add up to the total votes for that sex?\n",
    "for sex in [\"M\", \"F\"]:\n",
    "    brackets_sum = 0\n",
    "    for bracket in [\"017\", \"1829\", \"3044\", \"45PLUS\"]:\n",
    "        brackets_sum += imdb_ratings[\"{}_{}_VOTES\".format(sex, bracket)]\n",
    "    sex_bracket_mismatch_type = (brackets_sum - imdb_ratings[\"{}_VOTES\".format(sex)]).apply(determine_mismatch)\n",
    "    print(sex_bracket_mismatch_type.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c274839-4aae-46ac-8161-b5ab717f34e0",
   "metadata": {},
   "source": [
    "Same story as above; for both sexes, in some cases the age bracket of voters wasn't known, and that's not a problem. Similarly, below we see that in the vast majority of cases, the sex of some voters wasn't known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0c186608-8e9b-4047-beb0-2f414d210700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smaller    85768\n",
      "Equal         87\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Sex: does the sum of M and F add up to VOTES?\n",
    "m_plus_f = imdb_ratings[\"M_VOTES\"] + imdb_ratings[\"F_VOTES\"] \n",
    "sex_mismatch_type = (m_plus_f - imdb[\"VOTES\"]).apply(determine_mismatch)\n",
    "print(sex_mismatch_type.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2312a12-f18d-4ada-8952-f0870f0b0786",
   "metadata": {},
   "source": [
    "Ultimately, what this all means is that these null-containing columns are fine; null values in columns representing averages should stay null, whereas we can drop any columns that represent the number of votes, because we won't be needing them anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "518783ab-6c7e-4700-8242-e2b12721e837",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [col for col in cols_with_nulls if col.endswith(\"_VOTES\")]\n",
    "imdb_ratings.drop(columns = cols_to_drop, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c0279e91-43eb-43de-ac2b-44c6b626b5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 85855 entries, 0 to 85854\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   ID                  85855 non-null  object \n",
      " 1   M_AVG_SCORE         85854 non-null  float64\n",
      " 2   M_017_AVG_SCORE     27411 non-null  float64\n",
      " 3   M_1829_AVG_SCORE    84390 non-null  float64\n",
      " 4   M_3044_AVG_SCORE    85843 non-null  float64\n",
      " 5   M_45PLUS_AVG_SCORE  85754 non-null  float64\n",
      " 6   F_AVG_SCORE         85774 non-null  float64\n",
      " 7   F_017_AVG_SCORE     22117 non-null  float64\n",
      " 8   F_1829_AVG_SCORE    79334 non-null  float64\n",
      " 9   F_3044_AVG_SCORE    84911 non-null  float64\n",
      " 10  F_45PLUS_AVG_SCORE  83057 non-null  float64\n",
      "dtypes: float64(10), object(1)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "imdb_ratings.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cebed91",
   "metadata": {},
   "source": [
    "### Merging the two datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff776f39-e09a-44c7-941a-80a98bac9156",
   "metadata": {},
   "source": [
    "All that is left to do at this point is to merge `imdb` with `imdb_ratings`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "65ecc9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 85855 entries, 0 to 85854\n",
      "Data columns (total 20 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   ID                  85855 non-null  object \n",
      " 1   TITLE               85855 non-null  object \n",
      " 2   RELEASE_YEAR        85855 non-null  int32  \n",
      " 3   GENRE               85855 non-null  object \n",
      " 4   LENGTH_MIN          85855 non-null  int64  \n",
      " 5   COUNTRY             85855 non-null  object \n",
      " 6   WAVG_SCORE          85855 non-null  float64\n",
      " 7   VOTES               85855 non-null  int64  \n",
      " 8   BUDGET_USD          13397 non-null  float64\n",
      " 9   GLOBAL_GROSS_USD    30955 non-null  float64\n",
      " 10  M_AVG_SCORE         85854 non-null  float64\n",
      " 11  M_017_AVG_SCORE     27411 non-null  float64\n",
      " 12  M_1829_AVG_SCORE    84390 non-null  float64\n",
      " 13  M_3044_AVG_SCORE    85843 non-null  float64\n",
      " 14  M_45PLUS_AVG_SCORE  85754 non-null  float64\n",
      " 15  F_AVG_SCORE         85774 non-null  float64\n",
      " 16  F_017_AVG_SCORE     22117 non-null  float64\n",
      " 17  F_1829_AVG_SCORE    79334 non-null  float64\n",
      " 18  F_3044_AVG_SCORE    84911 non-null  float64\n",
      " 19  F_45PLUS_AVG_SCORE  83057 non-null  float64\n",
      "dtypes: float64(13), int32(1), int64(2), object(4)\n",
      "memory usage: 13.4+ MB\n"
     ]
    }
   ],
   "source": [
    "imdb_merged = pd.merge(imdb, imdb_ratings, how = \"inner\", on = \"ID\")\n",
    "imdb_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe37c42c",
   "metadata": {},
   "source": [
    "The columns could use some rearrangement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5c5a44a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 85855 entries, 0 to 85854\n",
      "Data columns (total 20 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   ID                  85855 non-null  object \n",
      " 1   TITLE               85855 non-null  object \n",
      " 2   RELEASE_YEAR        85855 non-null  int32  \n",
      " 3   GENRE               85855 non-null  object \n",
      " 4   LENGTH_MIN          85855 non-null  int64  \n",
      " 5   COUNTRY             85855 non-null  object \n",
      " 6   BUDGET_USD          13397 non-null  float64\n",
      " 7   GLOBAL_GROSS_USD    30955 non-null  float64\n",
      " 8   WAVG_SCORE          85855 non-null  float64\n",
      " 9   VOTES               85855 non-null  int64  \n",
      " 10  M_AVG_SCORE         85854 non-null  float64\n",
      " 11  M_017_AVG_SCORE     27411 non-null  float64\n",
      " 12  M_1829_AVG_SCORE    84390 non-null  float64\n",
      " 13  M_3044_AVG_SCORE    85843 non-null  float64\n",
      " 14  M_45PLUS_AVG_SCORE  85754 non-null  float64\n",
      " 15  F_AVG_SCORE         85774 non-null  float64\n",
      " 16  F_017_AVG_SCORE     22117 non-null  float64\n",
      " 17  F_1829_AVG_SCORE    79334 non-null  float64\n",
      " 18  F_3044_AVG_SCORE    84911 non-null  float64\n",
      " 19  F_45PLUS_AVG_SCORE  83057 non-null  float64\n",
      "dtypes: float64(13), int32(1), int64(2), object(4)\n",
      "memory usage: 13.4+ MB\n"
     ]
    }
   ],
   "source": [
    "rearranged_columns = (imdb_merged.columns[0:6].to_list() + \n",
    "                      [\"BUDGET_USD\", \"GLOBAL_GROSS_USD\", \"WAVG_SCORE\", \"VOTES\"]                     \n",
    "                      + imdb_merged.columns[10:].to_list())\n",
    "imdb_final = imdb_merged.reindex(columns = rearranged_columns)\n",
    "imdb_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e826d6",
   "metadata": {},
   "source": [
    "The dataset can now be exported as its own CSV file, so that analyses can be done without having to rerun all the cleaning first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e3664c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_final.to_csv(\"imdb_final.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46761aac",
   "metadata": {},
   "source": [
    "Just a little test, to make sure the saved dataset reads just fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1eb547b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 85855 entries, 0 to 85854\n",
      "Data columns (total 20 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   ID                  85855 non-null  object \n",
      " 1   TITLE               85855 non-null  object \n",
      " 2   RELEASE_YEAR        85855 non-null  int64  \n",
      " 3   GENRE               85855 non-null  object \n",
      " 4   LENGTH_MIN          85855 non-null  int64  \n",
      " 5   COUNTRY             85855 non-null  object \n",
      " 6   BUDGET_USD          13397 non-null  float64\n",
      " 7   GLOBAL_GROSS_USD    30955 non-null  float64\n",
      " 8   WAVG_SCORE          85855 non-null  float64\n",
      " 9   VOTES               85855 non-null  int64  \n",
      " 10  M_AVG_SCORE         85854 non-null  float64\n",
      " 11  M_017_AVG_SCORE     27411 non-null  float64\n",
      " 12  M_1829_AVG_SCORE    84390 non-null  float64\n",
      " 13  M_3044_AVG_SCORE    85843 non-null  float64\n",
      " 14  M_45PLUS_AVG_SCORE  85754 non-null  float64\n",
      " 15  F_AVG_SCORE         85774 non-null  float64\n",
      " 16  F_017_AVG_SCORE     22117 non-null  float64\n",
      " 17  F_1829_AVG_SCORE    79334 non-null  float64\n",
      " 18  F_3044_AVG_SCORE    84911 non-null  float64\n",
      " 19  F_45PLUS_AVG_SCORE  83057 non-null  float64\n",
      "dtypes: float64(13), int64(3), object(4)\n",
      "memory usage: 13.1+ MB\n"
     ]
    }
   ],
   "source": [
    "imdb_test = pd.read_csv(\"imdb_final.csv\", header = 0)\n",
    "imdb_test.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
